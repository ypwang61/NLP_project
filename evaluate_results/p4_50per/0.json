{
  "ori_ocr_text": "Add",
  "ocr": "Add.",
  "result_list": [
    [
      "Add & Norm",
      " common terminology in transformer architectures referring to the addition and normalization steps after attention and feed-forward layers"
    ],
    [
      "Add and Normalize",
      " alternate phrasing of the same concept with a more explicit conjunction"
    ],
    [
      "Addition and Normalization",
      " full descriptive terms for the process"
    ]
  ],
  "edit_dis": {
    "ocr": 1,
    "top_1_guess": 7,
    "top_3_guess": 7,
    "top_1_reason": 136,
    "top_3_reason": 38
  },
  "rouge_score@rouge1": {
    "ocr": 1.0,
    "top_1_guess": 0.6666666666666666,
    "top_3_guess": 0.6666666666666666,
    "top_1_reason": 0.0,
    "top_3_reason": 0.0
  },
  "rouge_score@rouge2": {
    "ocr": 0.0,
    "top_1_guess": 0.0,
    "top_3_guess": 0.0,
    "top_1_reason": 0.0,
    "top_3_reason": 0.0
  },
  "rouge_score@rougeL": {
    "ocr": 1.0,
    "top_1_guess": 0.6666666666666666,
    "top_3_guess": 0.6666666666666666,
    "top_1_reason": 0.0,
    "top_3_reason": 0.0
  },
  "rouge_score@rougeLsum": {
    "ocr": 1.0,
    "top_1_guess": 0.6666666666666666,
    "top_3_guess": 0.6666666666666666,
    "top_1_reason": 0.0,
    "top_3_reason": 0.0
  },
  "Bert_sim@precision": {
    "ocr": 0.6181339025497437,
    "top_1_guess": 0.5272282361984253,
    "top_3_guess": 0.5272282361984253,
    "top_1_reason": 0.2658143639564514,
    "top_3_reason": 0.28958451747894287
  },
  "Bert_sim@recall": {
    "ocr": 0.682022213935852,
    "top_1_guess": 0.6512172818183899,
    "top_3_guess": 0.6512172818183899,
    "top_1_reason": 0.4133508801460266,
    "top_3_reason": 0.44149625301361084
  },
  "Bert_sim@f1": {
    "ocr": 0.6485083699226379,
    "top_1_guess": 0.5827000141143799,
    "top_3_guess": 0.5827000141143799,
    "top_1_reason": 0.3235577642917633,
    "top_3_reason": 0.34975746273994446
  }
}