{
  "ori_ocr_text": "Iteration VS. NMSE (dB)",
  "ocr": "(dRamlim ny IIMBE (6b))",
  "result_list": [
    [
      "Sampling by RIMBE",
      " context clues"
    ],
    [
      "Sampling by LMSE",
      " similar letter shapes"
    ],
    [
      "Sampling by IMSE",
      " pattern matching"
    ]
  ],
  "edit_dis": {
    "ocr": 17,
    "top_1_guess": 19,
    "top_3_guess": 17,
    "top_1_reason": 20,
    "top_3_reason": 20
  },
  "rouge_score@rouge1": {
    "ocr": 0.0,
    "top_1_guess": 0.0,
    "top_3_guess": 0.0,
    "top_1_reason": 0.0,
    "top_3_reason": 0.0
  },
  "rouge_score@rouge2": {
    "ocr": 0.0,
    "top_1_guess": 0.0,
    "top_3_guess": 0.0,
    "top_1_reason": 0.0,
    "top_3_reason": 0.0
  },
  "rouge_score@rougeL": {
    "ocr": 0.0,
    "top_1_guess": 0.0,
    "top_3_guess": 0.0,
    "top_1_reason": 0.0,
    "top_3_reason": 0.0
  },
  "rouge_score@rougeLsum": {
    "ocr": 0.0,
    "top_1_guess": 0.0,
    "top_3_guess": 0.0,
    "top_1_reason": 0.0,
    "top_3_reason": 0.0
  },
  "Bert_sim@precision": {
    "ocr": 0.4785056710243225,
    "top_1_guess": 0.4689379334449768,
    "top_3_guess": 0.5792207717895508,
    "top_1_reason": 0.5675103068351746,
    "top_3_reason": 0.5675103068351746
  },
  "Bert_sim@recall": {
    "ocr": 0.46085914969444275,
    "top_1_guess": 0.4329226315021515,
    "top_3_guess": 0.5331106185913086,
    "top_1_reason": 0.4393079876899719,
    "top_3_reason": 0.4393079876899719
  },
  "Bert_sim@f1": {
    "ocr": 0.46951666474342346,
    "top_1_guess": 0.45021113753318787,
    "top_3_guess": 0.5552099943161011,
    "top_1_reason": 0.49524685740470886,
    "top_3_reason": 0.49524685740470886
  }
}