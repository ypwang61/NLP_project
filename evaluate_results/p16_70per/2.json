{
  "ori_ocr_text": "Q function",
  "ocr": "function cetvork AV",
  "result_list": [
    [
      "Q function network AV",
      "Reason: The context of DNN and adversarial DRL algorithms suggests that this segment represents the Q function network related to the autonomous vehicle (AV) portion of the architecture), 2: (Q network AV, Reason: Likely a part of the system responsible for the Q learning process in relation to the AV), 3: (Q learning AV, Reason: Given that the model seeks to learn optimal actions for an AV, a component might relate to Q learning, a common reinforcement learning technique)."
    ]
  ],
  "edit_dis": {
    "ocr": 13,
    "top_1_guess": 11,
    "top_3_guess": 11,
    "top_1_reason": 468,
    "top_3_reason": 468
  },
  "Bert_sim": {
    "ocr": 0.38533976674079895,
    "top_1_guess": 0.6557688117027283,
    "top_3_guess": 0.6557688117027283,
    "top_1_reason": 0.4034281075000763,
    "top_3_reason": 0.4034281075000763
  },
  "rouge_score@rouge1": {
    "ocr": 0.4,
    "top_1_guess": 0.6666666666666666,
    "top_3_guess": 0.6666666666666666,
    "top_1_reason": 0.04938271604938272,
    "top_3_reason": 0.04938271604938272
  },
  "rouge_score@rouge2": {
    "ocr": 0.0,
    "top_1_guess": 0.5,
    "top_3_guess": 0.5,
    "top_1_reason": 0.02531645569620253,
    "top_3_reason": 0.02531645569620253
  },
  "rouge_score@rougeL": {
    "ocr": 0.4,
    "top_1_guess": 0.6666666666666666,
    "top_3_guess": 0.6666666666666666,
    "top_1_reason": 0.04938271604938272,
    "top_3_reason": 0.04938271604938272
  },
  "rouge_score@rougeLsum": {
    "ocr": 0.4,
    "top_1_guess": 0.6666666666666666,
    "top_3_guess": 0.6666666666666666,
    "top_1_reason": 0.04938271604938272,
    "top_3_reason": 0.04938271604938272
  }
}